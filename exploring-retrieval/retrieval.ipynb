{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Simple Local RAG\n",
    "\n",
    "This is a very exploration with Langchain, Langsmith and AWS Bedrock, on how to create basic RAG with a locally running ChromaDB instance loaded with a single source PDF document.\n",
    "\n",
    "Langsmith is not actually needed for the implementation but its useful if we want to trace whats going on in our application.\n",
    "\n",
    "### Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt --quiet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate to AWS and Langsmith and Load Envrionment Variables\n",
    "Follow the instuctions in the `README.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Environment Variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())  # load the environment variables from .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Bedrock\n",
    "creating a bedrock client which will be used by the Bedrock classes in Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# Get region and profile from env\n",
    "region = os.environ.get(\"AWS_REGION\", \"us-east-1\")\n",
    "\n",
    "# Create a Bedrock client\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Langsmith Client\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Documents \n",
    "\n",
    "In the real work loading data and vectorizing it to be used in a vectorstore is usually a done with a separate ETL(extract transform and load) process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('./docs', glob=\"**/*.md\", show_progress=True)\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the docs loaded we then need prepare the data by splitting the text into smaller chunks using \"recursive split\" method. Which splits the data into chunks based on count of characters and/or special characters including linebreaks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of splits: 10\n",
      "page_content=\"Isabel Anderson\\n\\nI'm a results-focused professional with a commitment to delivering excellence, who likes to learn about artificial intelligence. I love coding and continuously improving my skills.\\nTechnologies: Kotlin, Android Development, Jetpack\" metadata={'source': 'docs/isabel.md'}\n",
      "page_content=\"Eve Davis\\n\\nI'm a user-experience driven designer with a strong coding background, who likes to build personal projects. I love coding and continuously improving my skills.\\nTechnologies: Ruby, Rails, Sinatra\" metadata={'source': 'docs/eve.md'}\n",
      "page_content=\"Frank Wilson\\n\\nI'm a data-driven analyst with extensive experience in software development, who likes to stay up-to-date with industry trends. I love coding and continuously improving my skills.\\nTechnologies: PHP, Laravel, Symfony\" metadata={'source': 'docs/frank.md'}\n",
      "page_content=\"Dave Brown\\n\\nI'm a full-stack developer with a knack for learning new technologies, who likes to read tech blogs. I love coding and continuously improving my skills. I have worked for 5 years so I'm pretty senior.\\nTechnologies: C#, .NET Core, Entity Framework\" metadata={'source': 'docs/dave.md'}\n",
      "page_content=\"Bob Johnson\\n\\nI'm a creative problem solver with a passion for innovation, who likes to participate in coding hackathons. I love coding and continuously improving my skills.\\nTechnologies: JavaScript, React, Node.js\" metadata={'source': 'docs/bob.md'}\n",
      "page_content=\"Grace Miller\\n\\nI'm a motivated self-learner with a strong interest in cybersecurity, who likes to attend tech meetups and conferences. I love coding and continuously improving my skills.\\nTechnologies: TypeScript, Angular, Vue.js\" metadata={'source': 'docs/grace.md'}\n",
      "page_content=\"Alice Smith\\n\\nI'm an enthusiastic and team-oriented developer, who likes to explore new technologies. I love coding and continuously improving my skills.\\nTechnologies: Python, Django, Flask\" metadata={'source': 'docs/alice.md'}\n",
      "page_content=\"Carol Williams\\n\\nI'm a detail-oriented programmer who thrives in high-pressure environments, who likes to contribute to open source projects. I love coding and continuously improving my skills.\\nTechnologies: Java, Spring Boot, Hibernate\" metadata={'source': 'docs/carol.md'}\n",
      "page_content=\"Jack Thomas\\n\\nI'm an adaptive and efficient coder with a passion for automation, who likes to tinker with hardware and IoT devices. I love coding and continuously improving my skills.\\nTechnologies: C++, Qt, Boost\" metadata={'source': 'docs/jack.md'}\n",
      "page_content=\"Henry Taylor\\n\\nI'm a versatile software engineer who have worked for over 5 years and enjoys collaborative projects, who likes to practice competitive programming. I love coding and continuously improving my skills.\\nTechnologies: Swift, iOS Development, Xcode\" metadata={'source': 'docs/henry.md'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size = 50, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "print(f\"Total number of splits: {len(all_splits)}\")\n",
    "\n",
    "# you can iterate of the first 10 splits and print out each split to check your chunking is working as expected\n",
    "for split in all_splits:\n",
    "    print(split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the embeddings from the pdf document with Bedrock\n",
    "Creating vector embeddings from documents involves converting textual information into numerical form so that it can be processed and understood by machine learning models.\n",
    "\n",
    "The embedding model is used for both creating the embeddings of pdf documents which will be stored in the vector-store as well as for creating the embedding of the user question.\n",
    "\n",
    "Langchain has built in support for many different embedding models. https://python.langchain.com/docs/integrations/text_embedding/bedrock\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BedrockEmbeddings Model\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "embedding_model_id = \"amazon.titan-embed-text-v1\"\n",
    "\n",
    "embedding_model = BedrockEmbeddings(\n",
    "    client=bedrock_client,\n",
    "    model_id=embedding_model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing ChromaDB and generating the embeddings\n",
    "This chromadb instance will only be available in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Embeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits, embedding=embedding_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your local ChromaDB vector store as a Retriever\n",
    "This part of the code is where we normally connect to a datastore and set the data store as a retriever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 10, updating n_results = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Dave Brown\\n\\nI'm a full-stack developer with a knack for learning new technologies, who likes to read tech blogs. I love coding and continuously improving my skills. I have worked for 5 years so I'm pretty senior.\\nTechnologies: C#, .NET Core, Entity Framework\", metadata={'source': 'docs/dave.md'}),\n",
       " Document(page_content=\"Henry Taylor\\n\\nI'm a versatile software engineer who have worked for over 5 years and enjoys collaborative projects, who likes to practice competitive programming. I love coding and continuously improving my skills.\\nTechnologies: Swift, iOS Development, Xcode\", metadata={'source': 'docs/henry.md'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a retriever\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
    "\n",
    "# testing the retriever by similarity search\n",
    "# retriever.get_relevant_documents(\"which person has the most experience with JavaScript and has worked with data?\")\n",
    "retriever.get_relevant_documents(\"I'm looking for a full-stack developer that has worked for atleast 5 years?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling in a forked community prompt\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"mrkmod/rag-prompt\")\n",
    "\n",
    "from langchain_community.llms import Bedrock\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# experiment with different models if you like\n",
    "# llm_model_id = \"anthropic.claude-instant-v1\"\n",
    "llm_model_id = \"anthropic.claude-v2\"\n",
    "\n",
    "llm = Bedrock(\n",
    "    client=bedrock_client, model_id=llm_model_id\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Retrieval Chain\n",
    "# print(prompt.messages[0].prompt.template)\n",
    "question = \"I'm looking for a full-stack developer that has worked for atleast 5 years, which person is the best candidate?\"\n",
    "\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(result.result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
