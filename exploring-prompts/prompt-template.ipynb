{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage of Langchain's PromptTemplate\n",
    "Exploring what I can do with the basic prompt template.\n",
    "\n",
    "\"Prompt is the input to the model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing langchain into the virtual environment we can start playing around \n",
    "\n",
    "PromptTemplate schema:\n",
    "```python\n",
    "class PromptTemplate(\n",
    "    *,\n",
    "    name: str | None = None,\n",
    "    input_variables: List[str],\n",
    "    input_types: Dict[str, Any] = dict,\n",
    "    output_parser: BaseOutputParser | None = None,\n",
    "    partial_variables: Mapping[str, str | (() -> str)] = dict,\n",
    "    template: str,\n",
    "    template_format: Literal['f-string', 'jinja2'] = \"f-string\",\n",
    "    validate_template: bool = False\n",
    ")\n",
    "``````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why is the sky the color blue'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt = PromptTemplate.from_template(\"Why is the sky the color blue\")\n",
    "prompt.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With template and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why is the sky the color blue'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_string = \"Why is the {material} the color {color}\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=prompt_template_string)\n",
    "prompt_template.format(material=\"sky\", color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain and Runnable \n",
    "Many components, including Prompt implements the Runnable protocol. Which is a standard interface making it easier to define custom chains and invoke them in different ways. \n",
    "\n",
    "- Runnable https://api.python.langchain.com/en/stable/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Why is the sky the color blue')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_string = \"Why is the {material} the color {color}\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=prompt_template_string)\n",
    "prompt_chain = prompt\n",
    "prompt_chain.invoke({\"material\": \"sky\", \"color\": \"blue\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs\n",
    "could be useful to be able to visualize how the prompt is constucted, especially when constucting more complex chains. Thats why we can install a tool to draw out the built in `.get_graph()` in ascii. The graph function lets us explore inputs and outputs and the relationship between the complonents in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PromptTemplateOutput | \n",
      "+----------------------+ \n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_template = PromptTemplate.from_template(template=prompt_template_string)\n",
    "prompt_chain = prompt \n",
    "prompt_chain.get_graph().print_ascii()\n",
    "# prompt_chain.invoke({\"material\": \"sky\", \"color\": \"blue\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composability\n",
    "There are a few ways to compose the basic PromptTemplate. The basic ones are Join, Partials and Pipelines.\n",
    "\n",
    "- Partials https://python.langchain.com/docs/modules/model_io/prompts/partial\n",
    "- Pipeline https://python.langchain.com/docs/modules/model_io/prompts/pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a scientist studying colors.\\nYou get asked the following question: Why is the sky blue \\nWhat is your response?\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining prompts is basically like joining strings\n",
    "\n",
    "# Creating a prompt template that adds additional context\n",
    "context = PromptTemplate.from_template( \"\"\"You are a scientist studying colors.\"\"\")\n",
    "\n",
    "# Creating a basic prompt template\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You get asked the following question: {question} \n",
    "What is your response?\n",
    "\"\"\")\n",
    "\n",
    "# Composing the two templates\n",
    "composed_prompt = context + prompt\n",
    "# Adding validation input variables to the composed prompt\n",
    "composed_prompt.input_variables = [\"question\"]\n",
    "\n",
    "prompt_text = composed_prompt.format(question=\"Why is the sky blue\")\n",
    "print(prompt_text) # returns a string\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
