{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Splitting Strategies\n",
    "\n",
    "- Character Splitting\n",
    "- Recursive Splitting\n",
    "\n",
    "You can use this application https://chunkviz.up.railway.app made by https://github.com/gkamradt to visualize the splitting in character and recursive strategies.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character Text Spltting\n",
    "\n",
    "This is the simplest method. https://python.langchain.com/docs/modules/data_connection/document_transformers/character_text_splitter\n",
    "\n",
    "**Examples**:\n",
    "- first example: splitting the text on characters isn't very useful\n",
    "    as it may split the text in the middle of word, loosing semantic meaning. But could perhaps be useful if you have a specific separator where you need to split the data on.\n",
    "    \n",
    "- second example: if we split by newlines alone we get closer to sentence splitting. but chunk-sizing is often lost since the logic is; split on newline or max characters. This could be a problem if we want chunks of somewhat equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample text from the gen-ai-wiki pdf\n",
    "text = \"\"\"\n",
    "Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. \n",
    "\n",
    "Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 10\n",
      "page_content='Generative artificial intelligence'\n",
      "page_content='or generative AI is a type of arti'\n",
      "page_content='ficial intelligence (AI) system cap'\n",
      "page_content='able of generating text, images, or'\n",
      "page_content='other media in response to prompts'\n",
      "page_content='. \\n\\nGenerative AI models learn the'\n",
      "page_content='patterns and structure of their inp'\n",
      "page_content='ut training data, and then generate'\n",
      "page_content='new data that has similar characte'\n",
      "page_content='ristics.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# split the text into sentences based on the length of characters\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\",\n",
    "    chunk_size=35,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = splitter.create_documents([text])\n",
    "\n",
    "# print the length of the splits\n",
    "print(f'length: {len(splits)}') # prints the length of the split text\n",
    "for split in splits:\n",
    "    print(split) # prints the split text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 176, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 2\n",
      "characters: 175\n",
      "page_content='Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts.'\n",
      "characters: 144\n",
      "page_content='Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# split the text into sentences based on newline the next paragraph\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=100, # this is ignored when text is longer, since the separator is set to newline and the next paragraph cant be fit into 100 characters\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = splitter.create_documents([text])\n",
    "\n",
    "# print the length of the splits\n",
    "print(f'length: {len(splits)}') # prints the length of the split text\n",
    "for split in splits:\n",
    "    print(f'characters: {len(split.page_content)}')\n",
    "    print(split) # prints the split text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Character Splitting\n",
    "\n",
    "this medthod tries to split text in order until the chunks are small enough. The default separator list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This strategy is what most simple RAG tutorials out there seem to use.\n",
    "\n",
    "examples:\n",
    "- first example: using the default separator config we get chunks that have \n",
    "    a much closer character length. This produces better quality chunking (no more middle of sentence splits). In this case the smaller chunk-size and chunk-overlap also produce less semantic meaning per chunk. It would be best to set a larger chunk-size and increase overlap if any.\n",
    "\n",
    "- second example: when switching to loading a larger document, thinking about chunk-size and overlap could be more important in order to keep the size|number of chunks down. Often in a larger document there is a greater variation of words per sentence and newlines. This could be a matter of cost and performance concern later on; eg. when the chunks are passed to an embedding model and/or retrieved to provide semantic meaning around a topic. Embedding models often have smaller context widows than their larger text generation counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks: 12\n",
      "characters=34\n",
      "page_content=page_content='Generative artificial intelligence'\n",
      "characters=29\n",
      "page_content=page_content='or generative AI is a type of'\n",
      "characters=33\n",
      "page_content=page_content='a type of artificial intelligence'\n",
      "characters=33\n",
      "page_content=page_content='(AI) system capable of generating'\n",
      "characters=31\n",
      "page_content=page_content='text, images, or other media in'\n",
      "characters=29\n",
      "page_content=page_content='media in response to prompts.'\n",
      "characters=30\n",
      "page_content=page_content='Generative AI models learn the'\n",
      "characters=32\n",
      "page_content=page_content='learn the patterns and structure'\n",
      "characters=33\n",
      "page_content=page_content='structure of their input training'\n",
      "characters=32\n",
      "page_content=page_content='training data, and then generate'\n",
      "characters=34\n",
      "page_content=page_content='generate new data that has similar'\n",
      "characters=24\n",
      "page_content=page_content='similar characteristics.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# recursive text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=35, \n",
    "    chunk_overlap=10\n",
    "    )\n",
    "\n",
    "splits = text_splitter.create_documents([text])\n",
    "# print the length of the splits\n",
    "print(f'chunks: {len(splits)}')\n",
    "\n",
    "for chunk in splits:\n",
    "    print(f'characters={len(chunk.page_content)}')\n",
    "    print(f'page_content={chunk}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above examples text was loaded directly into `create_documents` which creates documents from a list of texts.\n",
    "\n",
    "To chunk a document loader based object, use another method called `split_documents` which works with objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# load the data from the gen-ai-wiki which is a 3 page pdf\n",
    "loader = PyPDFLoader(file_path=\"gen-ai-wiki.pdf\")\n",
    "# save the data to a variable for use later\n",
    "data = loader.load()\n",
    "data = data # get the first page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks: 28\n",
      "characters=250\n",
      "page_content='Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts.[1][2] Generative AI models learn the patterns and structure of their input' metadata={'source': 'gen-ai-wiki.pdf', 'page': 0}\n",
      "characters=253\n",
      "page_content='of their input training data, and then generate new data that has similar characteristics.[3][4] Notable generative AI systems include ChatGPT (and its variant Bing Chat), a chatbot built by OpenAI using their GPT-3 and GPT-4 foundational large language' metadata={'source': 'gen-ai-wiki.pdf', 'page': 0}\n",
      "characters=252\n",
      "page_content='large language models,[5] and Bard, a chatbot built by Google using their LaMDA foundation model.[6] Other generative AI models include artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7] Generative AI has potential' metadata={'source': 'gen-ai-wiki.pdf', 'page': 0}\n",
      "characters=253\n",
      "page_content='AI has potential applications across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.[8][9][10] Investment in generative AI surged during the early 2020s, with' metadata={'source': 'gen-ai-wiki.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# recursive text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256, \n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    "    )\n",
    "\n",
    "splits = text_splitter.split_documents(data)\n",
    "# print the length of the splits\n",
    "print(f'chunks: {len(splits)}')\n",
    "\n",
    "for chunk in splits[0:4]: # print the first 4 chunks\n",
    "    print(f'characters={len(chunk.page_content)}')\n",
    "    print(f'{chunk}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split by token count not characters**\n",
    "\n",
    "Tiktoken can be used to give a rough estimate of tokens used which can be used to influence where we split the text.\n",
    "\n",
    "Use it for embedding and when you want to ensure that max token count is not exceeded for the model. If you excceed the limit, data in a chunk will be cut off. \n",
    "\n",
    "\n",
    "Using token length changes the chunksize and makes sure that splits are not larger than chunk size of tokens allowed by the embedding model. \n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/split_by_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens used count: 2\n",
      "content chars count: 10\n",
      "tiktoken_splitter : page_content='Generative' metadata={'source': 'gen-ai-wiki.pdf', 'page': 0}\n",
      "----------------------\n",
      "tokens used count: 10\n",
      "content chars count: 56\n",
      "recursive_token_splitter : page_content='Generative artificial intelligence or generative AI is a' metadata={'source': 'gen-ai-wiki.pdf', 'page': 0}\n",
      "----------------------\n",
      "tokens used count: 491\n",
      "content chars count: 2350\n",
      "character_token_splitter : page_content='Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts.[1][2] Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics.[3][4] Notable generative AI systems include ChatGPT (and its variant Bing Chat), a chatbot built by OpenAI using their GPT-3 and GPT-4 foundational large language models,[5] and Bard, a chatbot built by Google using their LaMDA foundation model.[6] Other generative AI models include artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7] Generative AI has potential applications across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.[8][9][10] Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models.[1][11][12] However, there are also concerns about the potential misuse of generative AI, such as in creating fake news or deepfakes, which can be used to deceive or manipulate people.[13] History[edit] Main article: History of artificial intelligence \\nA picketer at the 2023 Writers Guild of America strike. While not a top priority, one of the WGA\\'s 2023 requests was \"regulations around the use of (generative) AI\".[14] Since its founding, the field of machine learning has used statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image and video processing, text analysis, speech recognition, and other tasks. However, most deep neural networks were trained as discriminative models performing classification tasks such as convolutional neural network-based image classification. In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative, rather than discriminative, models of complex data such as images. These deep generative models were the first able to output not only class labels for images, but to output entire images.[15]' metadata={'source': 'gen-ai-wiki.pdf', 'page': 0}\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, TokenTextSplitter, Tokenizer\n",
    "\n",
    "# a dictionary that holds the result of the different text splitters below\n",
    "results = {}\n",
    "\n",
    "# direct token text splitter, split on 2 tokens\n",
    "tiktoken_splitter = TokenTextSplitter(\n",
    "chunk_size=2, chunk_overlap=0\n",
    ")\n",
    "\n",
    "splits = tiktoken_splitter.split_documents(data)\n",
    "results[\"tiktoken_splitter\"] = splits[0]\n",
    "\n",
    "# recursive character text split with tokenization\n",
    "recursive_token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "chunk_size=10, chunk_overlap=0\n",
    ")\n",
    "\n",
    "splits = recursive_token_splitter.split_documents(data)\n",
    "results[\"recursive_token_splitter\"] = splits[0]\n",
    "\n",
    "# character text split with tokenization\n",
    "character_token_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "chunk_size=10, chunk_overlap=0\n",
    ")\n",
    "\n",
    "splits = character_token_splitter.split_documents(data)\n",
    "results[\"character_token_splitter\"] = splits[0]\n",
    "\n",
    "# extra helper function to get the number of tokens from a string\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "total_chunk_tokens = 0\n",
    "total_tokens_per_chunk = []\n",
    "\n",
    "# print the details of the results\n",
    "for key, chunk in results.items(): # print the first 4 chunks\n",
    "    \n",
    "    tokens = num_tokens_from_string(chunk.page_content)\n",
    "    total_chunk_tokens += tokens\n",
    "    total_tokens_per_chunk.append(tokens)\n",
    "    print(f'tokens used count: {tokens}')\n",
    "    print(f'content chars count: {len(chunk.page_content)}')\n",
    "    print(f'{key} : {chunk}')\n",
    "    print(\"----------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
